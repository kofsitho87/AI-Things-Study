{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.core.callbacks import CallbackManager\n",
    "from langfuse.llama_index import LlamaIndexCallbackHandler\n",
    "\n",
    "langfuse_callback_handler = LlamaIndexCallbackHandler(\n",
    "    public_key=\"pk-lf-29339a8f-8a05-4d10-9a0a-a4718f79a53d\",\n",
    "    secret_key=\"sk-lf-d1f94511-893b-456e-973e-f57b44d50a30\",\n",
    "    host=\"https://cloud.langfuse.com\"\n",
    ")\n",
    "Settings.callback_manager = CallbackManager([langfuse_callback_handler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load from pdf file\"\"\"\n",
    "\n",
    "from llama_index.readers.file import PyMuPDFReader\n",
    "\n",
    "root_path = \"/Users/heewungsong/Experiment/Visa_Rag\"\n",
    "\n",
    "visa_pdf_file_path = f\"{root_path}/Documents/E-9 Visa Guide_한국어.pdf\"\n",
    "visa_docs = PyMuPDFReader().load_data(file_path=visa_pdf_file_path, metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import TextNode\n",
    "import json\n",
    "\n",
    "metadata_json_path = \"../../../Documents/E-9_Visa_Guide_한국어_metadata.json\"\n",
    "with open(metadata_json_path, \"r\") as fp:\n",
    "    metadata_json = json.load(fp)\n",
    "\n",
    "visa_nodes = []\n",
    "for idx, visa_doc in enumerate(visa_docs):\n",
    "    node = TextNode(\n",
    "        text=visa_doc.text, \n",
    "        metadata={**metadata_json[idx], **visa_doc.metadata},\n",
    "        excluded_llm_metadata_keys=[\"page_label\", \"file_path\", \"total_pages\", \"file_type\", \"file_size\", \"creation_date\", \"last_modified_date\", \"source\", \"file_name\"],\n",
    "    )\n",
    "    visa_nodes.append(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save docs into Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:6333/collections/test_collection \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: GET http://localhost:6333/collections/test_collection \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/test_collection/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: PUT http://localhost:6333/collections/test_collection/points?wait=true \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient(\n",
    "    \"localhost\",\n",
    "    port=\"6333\",\n",
    "    # api_key=\"<qdrant-api-key>\", # For Qdrant Cloud, None for local instance\n",
    ")\n",
    "vector_store = QdrantVectorStore(client=client, collection_name=\"test_collection\")\n",
    "\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "qdrant_index = VectorStoreIndex.from_documents(visa_docs, storage_context=storage_context)\n",
    "base_index = VectorStoreIndex.from_documents(visa_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load docs from Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:6333/collections/test_collection \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: GET http://localhost:6333/collections/test_collection \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: GET http://localhost:6333/collections/test_collection \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.indices.vector_store.base import VectorStoreIndex\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "client = QdrantClient(\n",
    "    \"localhost\",\n",
    "    port=\"6333\",\n",
    "    # api_key=\"<qdrant-api-key>\", # For Qdrant Cloud, None for local instance\n",
    ")\n",
    "\n",
    "vector_store = QdrantVectorStore(client=client, collection_name=\"test_collection\")\n",
    "\n",
    "qdrant_index = VectorStoreIndex.from_vector_store(vector_store=vector_store)\n",
    "base_index = VectorStoreIndex.from_documents(visa_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "332d31ac563646b6a508f6f634373d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "base_index_from_textNodes = VectorStoreIndex(visa_nodes, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_retriever = qdrant_index.as_retriever(similarity_top_k=10)\n",
    "base_retriever = base_index.as_retriever(similarity_top_k=10)\n",
    "\n",
    "base_textNodes_retriever = base_index_from_textNodes.as_retriever(similarity_top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "from llama_index.core.schema import MetadataMode\n",
    "\n",
    "# def pretty_print_source_nodes(source_nodes):\n",
    "#     for r in source_nodes:\n",
    "#         display_source_node(r, source_length=100, show_source_metadata=True, metadata_mode=MetadataMode.NONE)\n",
    "\n",
    "\n",
    "def pretty_print_source_nodes(source_nodes):\n",
    "    for r in source_nodes:\n",
    "        source = r.metadata['source']\n",
    "        text = r.text.split(\"\\n\")[0]\n",
    "        print(f\"{source}: {text}\")\n",
    "        # print(f\"{r.text[:50]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-4-1106-preview\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5: 고용허가제해당자의사증발급허용업종및체류자격약호(기호): E-9 근로자를채용할수있는\n",
      "5: 육림업, 벌목업, 임업관련서비스업\n",
      "1: E-9 Visa Guide - 한국어\n",
      "6: 고용허가제해당자는사증발급인정서를받아야만E-9 사증을\n",
      "17: 고용허가제해당자의체류자격변경허가- 사증변경\n",
      "8: 유효기간1년)\n",
      "16: 고용허가제농업분야외국인근로자의근무처(직장) 추가\n",
      "5: 잡지및기타인쇄물출판업\n",
      "9: 고용허가제해당자의재입국특례제도(구성실근로자제도)\n",
      "14: 고용허가제해당자가근무처(직장)를변경할수있는조건\n",
      "--------------------------------------------------------------------------------------------------------------------\n",
      "5: 고용허가제해당자의사증발급허용업종및체류자격약호(기호): E-9 근로자를채용할수있는\n",
      "5: 육림업, 벌목업, 임업관련서비스업\n",
      "1: E-9 Visa Guide - 한국어\n",
      "6: 고용허가제해당자는사증발급인정서를받아야만E-9 사증을\n",
      "17: 고용허가제해당자의체류자격변경허가- 사증변경\n",
      "8: 유효기간1년)\n",
      "16: 고용허가제농업분야외국인근로자의근무처(직장) 추가\n",
      "5: 잡지및기타인쇄물출판업\n",
      "9: 고용허가제해당자의재입국특례제도(구성실근로자제도)\n",
      "14: 고용허가제해당자가근무처(직장)를변경할수있는조건\n",
      "--------------------------------------------------------------------------------------------------------------------\n",
      "5: 고용허가제해당자의사증발급허용업종및체류자격약호(기호): E-9 근로자를채용할수있는\n",
      "6: 고용허가제해당자는사증발급인정서를받아야만E-9 사증을\n",
      "17: 고용허가제해당자의체류자격변경허가- 사증변경\n",
      "21: 고용허가제해당자의고용변동신고\n",
      "8: 고용허가제비전문취업(E-9) 자격사증발급인정서발급절차\n",
      "1: E-9 Visa Guide - 한국어\n",
      "9: 고용허가제해당자의재입국특례제도(구성실근로자제도)\n",
      "13: 고용허가제해당자의근무처(직장)의변경\n",
      "14: 고용허가제해당자가근무처(직장)를변경할수있는조건\n",
      "7: 고용허가제해당자는2012.8.1부터범죄경력증명서및\n"
     ]
    }
   ],
   "source": [
    "query = \"저는 한국에 살고 있는 외국인인데, 직업을 바꾸는게 가능한가요?\"\n",
    "query = \"한국에서 건물 청소하는 일을 할 예정인데 건물 청소는 어떤 업종이고 체류자격의 비자 타입은 무엇인가요?\"\n",
    "query = \"현재 농장에서 일하고 있는데 이 분야가 계절적 특성을 타기 때문에 다음주 부턴 일이 없는데, 다른 분야의 사업장에 일을 구하는게 가능한가요?\"\n",
    "query = \"올해부터 E9 비자로 식당에서 일을 할 수 있는 것 맞나요?\"\n",
    "\n",
    "source_nodes1 = qdrant_retriever.retrieve(query)\n",
    "pretty_print_source_nodes(source_nodes=source_nodes1)\n",
    "\n",
    "print(f\"--------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "source_nodes2 = base_retriever.retrieve(query)\n",
    "pretty_print_source_nodes(source_nodes=source_nodes2)\n",
    "\n",
    "print(f\"--------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "source_nodes3 = base_textNodes_retriever.retrieve(query)\n",
    "pretty_print_source_nodes(source_nodes=source_nodes3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_query_engine = qdrant_index.as_query_engine()\n",
    "base_textNode_engine = base_index_from_textNodes.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_query(query: str):\n",
    "    langfuse_callback_handler.set_trace_params(\n",
    "        name=query,\n",
    "        version=\"1\",\n",
    "        tags=[\"Visa Guide Doc\", \"QdrantEngine\"]\n",
    "    )\n",
    "    response = qdrant_query_engine.query(query)\n",
    "    print(f\"QdrantEngine: {response}\\n\\n\")\n",
    "\n",
    "    langfuse_callback_handler.set_trace_params(\n",
    "        name=query,\n",
    "        version=\"2\",\n",
    "        tags=[\"Visa Guide Doc\", \"BaseTextNodeEngine\"]\n",
    "    )\n",
    "    response = base_textNode_engine.query(query)\n",
    "    print(f\"BaseTextNodeEngine: {response}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QdrantEngine: 네, 올해부터 E-9 비자를 가진 외국인 근로자가 특정 조건을 충족하는 식당에서 일할 수 있습니다. 해당 조건은 음식점업 외국인력 허용 시범지역에 소재한 내국인 피보험자 수 5인 이상 사업장 중 5년 이상 영업을 유지하고 있는 사업체 또는 내국인 피보험자 수 5인 미만 사업장 중 7년 이상 영업을 유지하고 있는 사업체에 한합니다. 또한, 표준직업분류상 ‘주방보조원’ 고용에 한함을 명시하고 있습니다.\n",
      "\n",
      "\n",
      "BaseTextNodeEngine: 올해부터 '한식음식점업'에서 E-9 비자를 가진 근로자를 고용할 수 있습니다.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"저는 한국에 살고 있는 외국인인데, 직업을 바꾸는게 가능한가요?\"\n",
    "query = \"한국에서 건물 청소하는 일을 할 예정인데 건물 청소는 어떤 업종이고 체류자격의 비자 타입은 무엇인가요?\"\n",
    "query = \"현재 농장에서 일하고 있는데 이 분야가 계절적 특성을 타기 때문에 다음주 부턴 일이 없는데, 다른 분야의 사업장에 일을 구하는게 가능한가요?\"\n",
    "query = \"올해부터 E9 비자로 식당에서 일을 할 수 있는 것 맞나요?\"\n",
    "\n",
    "llm_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Embedding Size and Distance from OpenAIEmbedding\n",
    "\n",
    "In this code, we first create an OpenAIEmbedding model and use it to get the embedding for a given text. \n",
    "\n",
    "Then, we create a QdrantClient instance to interact with the Qdrant server. \n",
    "\n",
    "We set the size of the vector storage in Qdrant to the number of dimensions in the embedding, which is obtained from the shape of the embedding. Finally, we create a collection in Qdrant with the specified vector parameters.\n",
    "\n",
    "\n",
    "Note that the distance metric is set to models.Distance.COSINE in this example, but you can choose a different distance metric depending on your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "# Create an OpenAI embedding model\n",
    "embedding_model = OpenAIEmbedding()\n",
    "\n",
    "# Get the embedding for a given text\n",
    "text = \"Your text to get the embedding for\"\n",
    "embedding = embedding_model.embed_text(text)\n",
    "\n",
    "# Create a Qdrant client\n",
    "qdrant_client = QdrantClient(\"localhost\", port=6334)\n",
    "\n",
    "# Set the size and distance for the vector storage in Qdrant\n",
    "vector_params = models.VectorParams(\n",
    "    size=embedding.shape[0],  # Get the size from the shape of the embedding\n",
    "    distance=models.Distance.COSINE\n",
    ")\n",
    "\n",
    "# Create a collection in Qdrant with the specified vector parameters\n",
    "collection_name = \"your_collection_name\"\n",
    "qdrant_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=vector_params\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visa_chatbot1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
