{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8l/h9gthwnn40gcs_zb4k3g4_z40000gn/T/ipykernel_50303/693524478.py:2: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  sc = ServiceContext.from_defaults()\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import ServiceContext\n",
    "sc = ServiceContext.from_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from llama_index.core import VectorStoreIndex, load_index_from_storage\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "db = chromadb.PersistentClient(path=\"../Storing/chroma\")\n",
    "\n",
    "# collection_name = \"E9_VISA_GUIDE_AND_FAQ\" # Guide + FAQ\n",
    "collection_name = \"E9_VISA_GUIDE\" # Guide\n",
    "# collection_name = \"E9_VISA_FAQ\" # FAQ\n",
    "\n",
    "chroma_collection = db.get_collection(collection_name)\n",
    "chroma_vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "\n",
    "embed_model = OpenAIEmbedding()\n",
    "index = VectorStoreIndex.from_vector_store(vector_store=chroma_vector_store, embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = index.as_retriever(\n",
    "    similarity_top_k=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_nodes(nodes):\n",
    "    for node in nodes:\n",
    "        print(f\"\\nScore: {node.score:.3f}\")\n",
    "        print(f\"Title: {node.metadata['document_title']}\")\n",
    "        print(node.get_content()[:100])\n",
    "        print(\"\\n--------------------------------------------------------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "\n",
      "Score: 0.748\n",
      "Title: 고용허가제 해당자의 고용변동 신고\n",
      "고용허가제 해당자의 고용변동 신고\n",
      "        ● 신고의무자\n",
      "            ○ 비전문취업(E-9) 외국인근로자를 고용한 자\n",
      "        ● 신고기한\n",
      "           \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Score: 0.737\n",
      "Title: 고용허가제 해당자가 근무처(직장)를 변경할 수 있는 조건\n",
      "고용허가제 해당자가 근무처(직장)를 변경할 수 있는 조건\n",
      "        ● 출입국관리법」제21조 및 「외국인고용법」제25조에 의거, 비전문취업자의 근무처 변경에 대한 허가권자는 법\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Score: 0.718\n",
      "Title: 고용허가제 해당자의 근무처(직장)의 변경\n",
      "고용허가제 해당자의 근무처(직장)의 변경\n",
      "        ● 출입국관리법」제21조 및 「외국인고용법」제25조에 의거, 비전문취업자의 근무처 변경에 대한 허가권자는 법무부장관임\n",
      "   \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Score: 0.715\n",
      "Title: 고용허가제 농업 분야 외국인근로자의 근무처(직장) 추가\n",
      "고용허가제 농업 분야 외국인근로자의 근무처(직장) 추가\n",
      "        ● 계절적으로 업무량의 차이가 큰 일부 농업분야에 근무하는 외국인근로자가 원사업장과의 근로계약은 유지하면서(무\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Score: 0.713\n",
      "Title: 고용허가제 해당자가 근무처(직장)를 변경하는 절차 및 제출 서류\n",
      "고용허가제 해당자가 근무처(직장)를 변경하는 절차 및 제출 서류\n",
      "        ● 근무처(직장) 변경 절차\n",
      "            ○ 사용자와 근로계약 종료 후 1월 이내에 사업장 \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Score: 0.704\n",
      "Title: 고용허가제 해당자와 활동범위\n",
      "고용허가제 해당자와 활동범위\n",
      "            - 활동범위\n",
      "                외국인근로자의 고용 등에 관한 법률의 규정에 의한 국내취업\n",
      "            - 해당\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Score: 0.704\n",
      "Title: 고용허가제 법률적 개요와 고용허가제 선정국가\n",
      "고용허가제 \n",
      "            - ｢외국인근로자의 고용 등에 관한 법률｣에 의거, 사업주에게 외국인근로자의 고용을 허가하고, 외국인 근로자에게는 당해 사업주에게 고용되는 조건으\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Score: 0.701\n",
      "Title: 재입국특례자에 대한 우대 내용\n",
      "재입국특례자에 대한 우대 내용\n",
      "        ● 사업주\n",
      "            ○ (내국인 구인노력 면제) 고용허가서 발급 시 사업주의 내국인 구인노력 불요\n",
      "            ○\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Score: 0.692\n",
      "Title: 재입국특례 제도(구 성실근로자 제도)\n",
      "재입국특례 제도(구 성실근로자 제도)\n",
      "        ● 재입국 특례 제도란\n",
      "            ○ 일정한 요건을 갖춘 성실외국인 근로자가 취업활동 기간이 만료되어 출국하기 전에 \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Score: 0.681\n",
      "Title: 고용허가제 해당자의 재입국허가\n",
      "고용허가제 해당자의 재입국허가\n",
      "        ● 재입국허가 면제 제도 시행(’10.12.1.자 개정 시행규칙)\n",
      "            ○ 등록을 필한 외국인이 출국한 날부터 1년 이\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# query = \"베트남에서 E9 비자 발급하고 싶은데 무엇을 준비해야 되나여?\" # long(X) 나머지 ok\n",
    "# query = \"한국에서 일하려고 하는데 주로 무슨 업종이 있나요\" #cohere, long + sentence, origin\n",
    "# query = \"비전문취업자의 직장변경은 몇회까지 가능한가요?\" # long(X) 나머지 ok\n",
    "# query = \"저는 베트남에서 쌀국수 식당에서 조리사로 일하고 있는데 한국에서 요리사로 취업이 가능할까요?\" #origin + sentence\n",
    "# query = \"농축산업에서 일하려고 하는데 준비해야하는 서류는 무엇이있나요?\" #cohere\n",
    "# query = \"고용허가제를 통해 E-9비자로 한국의 농축산업에서 일하려고 하는데 준비해야하는 서류는 무엇이있나요?\" #cohere\n",
    "# query = \"저는 베트남에서 한국으로 취업을 희망하는 학생입니다. 한국의 농장에서 일하려고 하는데 준비해야하는 절차는 무엇이 있나요?\" #cohere + long\n",
    "query = \"E9비자 체류기간 연장 허가와 관련해서 기숙사비 영수증은 무슨용도의 서류인가요?\" # long(X) 나머지 ok\n",
    "query = \"E9비자와 관련해서 한국에 더 머무르는 허가를 받기위해 제출해야 하는 서류는 무엇인가요?\" # cohere\n",
    "query = \"직장의 이름이 변경되었을때도 고용변동에 대한 신고를 해야하나요?\" # long(X) 나머지 ok\n",
    "query = \"저는 성실근로자 재입국 취업 대상자인데 베트남으로 다시 돌아갈때 외국인등록증을 반납해야 하나요?\" # cohere\n",
    "query = \"저는 한국에서 일하고 있는 외국인 노동자입니다. 지금 일하는 곳의 사장님이 회사이름을 변경하였는데 제가 어떤 신고를 해야될게 있나요?\" # cohere\n",
    "\n",
    "nodes = retriever.retrieve(query)\n",
    "\n",
    "print_nodes(nodes)\n",
    "# save_to_json(query, nodes, {\"similarity_top_k\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def save_to_json(query, origin, cohere, long, sentence, lingua):\n",
    "    origin_sources = [\n",
    "        # {\n",
    "        #     \"rank\": idx + 1,\n",
    "        #     \"document_title\": node.metadata['document_title'],\n",
    "        #     \"score\": round(node.score, 3),\n",
    "        # }\n",
    "        node.metadata['document_title'] \n",
    "        for idx, node in enumerate(origin)\n",
    "    ]\n",
    "    cohere_sources = [\n",
    "        # {\n",
    "        #     \"rank\": idx + 1,\n",
    "        #     \"document_title\": node.metadata['document_title'],\n",
    "        #     \"score\": round(node.score, 3),\n",
    "        # }\n",
    "        node.metadata['document_title'] \n",
    "        for idx, node in enumerate(cohere)\n",
    "    ]\n",
    "    long_sources = [\n",
    "        # {\n",
    "        #     \"rank\": idx + 1,\n",
    "        #     \"document_title\": node.metadata['document_title'],\n",
    "        #     \"score\": round(node.score, 3),\n",
    "        # }\n",
    "        node.metadata['document_title'] \n",
    "        for idx, node in enumerate(long)\n",
    "    ]\n",
    "    sentence_sources = [\n",
    "        # {\n",
    "        #     \"rank\": idx + 1,\n",
    "        #     \"document_title\": node.metadata['document_title'],\n",
    "        #     \"score\": round(node.score, 3),\n",
    "        # }\n",
    "        node.metadata['document_title'] \n",
    "        for idx, node in enumerate(sentence)\n",
    "    ]\n",
    "    lingua_sources = [\n",
    "        # {\n",
    "        #     \"rank\": idx + 1,\n",
    "        #     \"document_title\": node.metadata['document_title'],\n",
    "        #     \"score\": round(node.score, 3),\n",
    "        # }\n",
    "        node.metadata['document_title'] \n",
    "        for idx, node in enumerate(lingua)\n",
    "    ]\n",
    "    with open(f\"./query_test_set/{query}.json\", 'w') as json_file:\n",
    "        json.dump(\n",
    "            {\"query\": query, \"origin_sources\": origin_sources, \"cohere_sources\": cohere_sources, \"long_sources\": long_sources, \"sentence_sources\": sentence_sources, \"lingua_sources\": lingua_sources}, \n",
    "            json_file, \n",
    "            ensure_ascii=False, \n",
    "            indent=4\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llmlingua in /Users/heewungsong/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages (0.2.1)\n",
      "Requirement already satisfied: transformers>=4.26.0 in /Users/heewungsong/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages (from llmlingua) (4.39.1)\n",
      "Requirement already satisfied: accelerate in /Users/heewungsong/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages (from llmlingua) (0.28.0)\n",
      "Requirement already satisfied: torch in /Users/heewungsong/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages (from llmlingua) (2.2.2)\n",
      "Requirement already satisfied: tiktoken in /Users/heewungsong/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages (from llmlingua) (0.6.0)\n",
      "Requirement already satisfied: nltk in /Users/heewungsong/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages (from llmlingua) (3.8.1)\n",
      "Requirement already satisfied: numpy in /Users/heewungsong/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages (from llmlingua) (1.26.4)\n",
      "Requirement already satisfied: filelock in /Users/heewungsong/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages (from transformers>=4.26.0->llmlingua) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/heewungsong/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages (from transformers>=4.26.0->llmlingua) (0.21.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/heewungsong/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages (from transformers>=4.26.0->llmlingua) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/heewungsong/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages (from transformers>=4.26.0->llmlingua) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/heewungsong/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages (from transformers>=4.26.0->llmlingua) (2023.12.25)\n",
      "Requirement already satisfied: requests in /Users/heewungsong/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages (from transformers>=4.26.0->llmlingua) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/heewungsong/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages (from transformers>=4.26.0->llmlingua) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/heewungsong/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages (from transformers>=4.26.0->llmlingua) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/heewungsong/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages (from transformers>=4.26.0->llmlingua) (4.66.2)\n",
      "Requirement already satisfied: psutil in /Users/heewungsong/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages (from accelerate->llmlingua) (5.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/heewungsong/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages (from torch->llmlingua) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/heewungsong/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages (from torch->llmlingua) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/heewungsong/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages (from torch->llmlingua) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/heewungsong/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages (from torch->llmlingua) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/heewungsong/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages (from torch->llmlingua) (2024.2.0)\n",
      "Requirement already satisfied: click in /Users/heewungsong/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages (from nltk->llmlingua) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/heewungsong/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages (from nltk->llmlingua) (1.3.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/heewungsong/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages (from requests->transformers>=4.26.0->llmlingua) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/heewungsong/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages (from requests->transformers>=4.26.0->llmlingua) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/heewungsong/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages (from requests->transformers>=4.26.0->llmlingua) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/heewungsong/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages (from requests->transformers>=4.26.0->llmlingua) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/heewungsong/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages (from jinja2->torch->llmlingua) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/heewungsong/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages (from sympy->torch->llmlingua) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install dependency.\n",
    "%pip install llmlingua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f5ba29f1ca43288d84e022e1ce9499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 18\u001b[0m\n\u001b[1;32m     11\u001b[0m long_postprocessor \u001b[38;5;241m=\u001b[39m LongContextReorder()\n\u001b[1;32m     12\u001b[0m sentence_postprocessor \u001b[38;5;241m=\u001b[39m SentenceEmbeddingOptimizer(\n\u001b[1;32m     13\u001b[0m     embed_model\u001b[38;5;241m=\u001b[39msc\u001b[38;5;241m.\u001b[39membed_model,\n\u001b[1;32m     14\u001b[0m     percentile_cutoff\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# threshold_cutoff=0.7\u001b[39;00m\n\u001b[1;32m     16\u001b[0m )\n\u001b[0;32m---> 18\u001b[0m lingua_postprocessor \u001b[38;5;241m=\u001b[39m \u001b[43mLongLLMLinguaPostprocessor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstruction_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGiven the context, please answer the final question\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrank_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlongllmlingua\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_compress_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcondition_compare\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcondition_in_question\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mafter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext_budget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m+100\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreorder_context\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# enable document reorder\u001b[39;49;00m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages/llama_index/postprocessor/longllmlingua/base.py:56\u001b[0m, in \u001b[0;36mLongLLMLinguaPostprocessor.__init__\u001b[0;34m(self, model_name, device_map, model_config, open_api_config, metadata_mode, instruction_str, target_token, rank_method, additional_compress_kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m open_api_config \u001b[38;5;241m=\u001b[39m open_api_config \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m     54\u001b[0m additional_compress_kwargs \u001b[38;5;241m=\u001b[39m additional_compress_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm_lingua \u001b[38;5;241m=\u001b[39m \u001b[43mPromptCompressor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopen_api_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopen_api_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     63\u001b[0m     metadata_mode\u001b[38;5;241m=\u001b[39mmetadata_mode,\n\u001b[1;32m     64\u001b[0m     instruction_str\u001b[38;5;241m=\u001b[39minstruction_str,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m     additional_compress_kwargs\u001b[38;5;241m=\u001b[39madditional_compress_kwargs,\n\u001b[1;32m     68\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages/llmlingua/prompt_compressor.py:88\u001b[0m, in \u001b[0;36mPromptCompressor.__init__\u001b[0;34m(self, model_name, device_map, model_config, open_api_config, use_llmlingua2, llmlingua2_config)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefix_bos_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moai_tokenizer \u001b[38;5;241m=\u001b[39m tiktoken\u001b[38;5;241m.\u001b[39mencoding_for_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_llmlingua2:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_llmlingua2(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mllmlingua2_config)\n",
      "File \u001b[0;32m~/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages/llmlingua/prompt_compressor.py:139\u001b[0m, in \u001b[0;36mPromptCompressor.load_model\u001b[0;34m(self, model_name, device_map, model_config)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    134\u001b[0m     device_map\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(key \u001b[38;5;129;01min\u001b[39;00m device_map \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    137\u001b[0m )\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map:\n\u001b[0;32m--> 139\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mMODEL_CLASS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtorch_dtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m     model \u001b[38;5;241m=\u001b[39m MODEL_CLASS\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    151\u001b[0m         model_name,\n\u001b[1;32m    152\u001b[0m         device_map\u001b[38;5;241m=\u001b[39mdevice_map,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_config,\n\u001b[1;32m    156\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:563\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    562\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages/transformers/modeling_utils.py:3531\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3522\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3523\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   3524\u001b[0m     (\n\u001b[1;32m   3525\u001b[0m         model,\n\u001b[1;32m   3526\u001b[0m         missing_keys,\n\u001b[1;32m   3527\u001b[0m         unexpected_keys,\n\u001b[1;32m   3528\u001b[0m         mismatched_keys,\n\u001b[1;32m   3529\u001b[0m         offload_index,\n\u001b[1;32m   3530\u001b[0m         error_msgs,\n\u001b[0;32m-> 3531\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3534\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   3535\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3536\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3537\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3538\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3539\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3542\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3543\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3547\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3549\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   3550\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m~/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages/transformers/modeling_utils.py:3958\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m   3954\u001b[0m                 set_module_tensor_to_device(\n\u001b[1;32m   3955\u001b[0m                     model_to_load, key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m*\u001b[39mparam\u001b[38;5;241m.\u001b[39msize(), dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   3956\u001b[0m                 )\n\u001b[1;32m   3957\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3958\u001b[0m         new_error_msgs, offload_index, state_dict_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3959\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3960\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3961\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloaded_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3962\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3963\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3964\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3965\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3966\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3967\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3968\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3969\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3970\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3971\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3972\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3973\u001b[0m \u001b[43m            \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3974\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3975\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_error_msgs\n\u001b[1;32m   3976\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages/transformers/modeling_utils.py:812\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, loaded_state_dict_keys, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, hf_quantizer, is_safetensors, keep_in_fp32_modules, unexpected_keys)\u001b[0m\n\u001b[1;32m    801\u001b[0m     state_dict_index \u001b[38;5;241m=\u001b[39m offload_weight(param, param_name, state_dict_folder, state_dict_index)\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    803\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m is_quantized\n\u001b[1;32m    804\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m hf_quantizer\u001b[38;5;241m.\u001b[39mrequires_parameters_quantization)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    810\u001b[0m ):\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;66;03m# For backward compatibility with older versions of `accelerate` and for non-quantized params\u001b[39;00m\n\u001b[0;32m--> 812\u001b[0m     \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mset_module_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    814\u001b[0m     hf_quantizer\u001b[38;5;241m.\u001b[39mcreate_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)\n",
      "File \u001b[0;32m~/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages/accelerate/utils/modeling.py:387\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    385\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 387\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    389\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/anaconda3/envs/visa_chatbot1/lib/python3.11/site-packages/torch/cuda/__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    291\u001b[0m     )\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    296\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "from llama_index.core.postprocessor import LongContextReorder\n",
    "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
    "from llama_index.core.postprocessor import SentenceEmbeddingOptimizer\n",
    "from llama_index.postprocessor.longllmlingua import LongLLMLinguaPostprocessor\n",
    "\n",
    "\n",
    "\n",
    "cohere_postprocessor = CohereRerank(\n",
    "    top_n=5, model=\"rerank-multilingual-v2.0\"\n",
    ")\n",
    "long_postprocessor = LongContextReorder()\n",
    "sentence_postprocessor = SentenceEmbeddingOptimizer(\n",
    "    embed_model=sc.embed_model,\n",
    "    percentile_cutoff=0.7,\n",
    "    # threshold_cutoff=0.7\n",
    ")\n",
    "\n",
    "# lingua_postprocessor = LongLLMLinguaPostprocessor(\n",
    "#     instruction_str=\"Given the context, please answer the final question\",\n",
    "#     target_token=300,\n",
    "#     rank_method=\"longllmlingua\",\n",
    "#     additional_compress_kwargs={\n",
    "#         \"condition_compare\": True,\n",
    "#         \"condition_in_question\": \"after\",\n",
    "#         \"context_budget\": \"+100\",\n",
    "#         \"reorder_context\": \"sort\",  # enable document reorder\n",
    "#     },\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lingua_postprocessor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m long_reorder_nodes \u001b[38;5;241m=\u001b[39m long_postprocessor\u001b[38;5;241m.\u001b[39mpostprocess_nodes(nodes, query_str\u001b[38;5;241m=\u001b[39mquery)\n\u001b[1;32m      3\u001b[0m sentence_reorder_nodes \u001b[38;5;241m=\u001b[39m sentence_postprocessor\u001b[38;5;241m.\u001b[39mpostprocess_nodes(nodes, query_str\u001b[38;5;241m=\u001b[39mquery)\n\u001b[0;32m----> 5\u001b[0m lingua_reorder_nodes \u001b[38;5;241m=\u001b[39m \u001b[43mlingua_postprocessor\u001b[49m\u001b[38;5;241m.\u001b[39mpostprocess_nodes(nodes, query_str\u001b[38;5;241m=\u001b[39mquery)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# print_nodes(reorder_nodes)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m save_to_json(query, nodes, cohere_reorder_nodes, long_reorder_nodes, sentence_reorder_nodes, lingua_reorder_nodes)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lingua_postprocessor' is not defined"
     ]
    }
   ],
   "source": [
    "cohere_reorder_nodes = cohere_postprocessor.postprocess_nodes(nodes, query_str=query)\n",
    "long_reorder_nodes = long_postprocessor.postprocess_nodes(nodes, query_str=query)\n",
    "sentence_reorder_nodes = sentence_postprocessor.postprocess_nodes(nodes, query_str=query)\n",
    "\n",
    "# lingua_reorder_nodes = lingua_postprocessor.postprocess_nodes(nodes, query_str=query)\n",
    "\n",
    "\n",
    "# print_nodes(reorder_nodes)\n",
    "save_to_json(query, nodes, cohere_reorder_nodes, long_reorder_nodes, sentence_reorder_nodes, lingua_reorder_nodes)\n",
    "\n",
    "# reorder_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visa_chatbot1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
